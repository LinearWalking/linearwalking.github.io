<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta property="og:title" content="The Surprising Effectiveness of Linear Models for Whole-Body Model-Predictive Control">
  <meta property="og:description" content="Hardware and simulation results of a Convex-MPC controller for legged robots.">
  <meta property="og:url" content="https://linear-walking.github.io/"/>
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>
  <meta name="twitter:title" content="The Surprising Effectiveness of Linear Models for Whole-Body Model-Predictive Control">
  <meta name="twitter:description" content="Hardware and simulation results of a Convex-MPC controller for legged robots.">
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="keywords" content="robotics, quadruped, legged robots, control, sampling-based control, model predictive control, MPPI, whole-body control, locomotion, trajectory optimization, Go1, Unitree, hardware experiments, Gazebo simulation, MuJoCo, reinforcement learning, trajectory tracking">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>The Surprising Effectiveness of Linear Models for Whole-Body Model-Predictive Control</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>

  <!-- MathJax for LaTeX rendering -->
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">The Surprising Effectiveness of Linear Models for Whole-Body Model-Predictive Control (under construction)</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><a href="https://www.ri.cmu.edu/ri-people/arun-bishop/" target="_blank">Arun Bishop</a></span>,
            <span class="author-block"><a href="https://jrapudg.github.io/" target="_blank">Juan Alvarez-Padilla</a></span>,
            <span class="author-block">Sam Schoedel</span>,
            <span class="author-block">Ibrahima Sory Sow</span>,
            <span class="author-block">Juee Chandrachud</span>,
            <span class="author-block">Sheitej Sharma</span>,
            <span class="author-block">Will Kraus</span>,
            <span class="author-block">Beomyeong Park</span>,
            <span class="author-block">Robert J. Griffin</span>,
            <span class="author-block"><a href="https://www.ri.cmu.edu/ri-faculty/john-m-dolan/" target="_blank">John M. Dolan</a></span>, and 
            <span class="author-block"><a href="https://rexlab.ri.cmu.edu/" target="_blank">Zachary Manchester</a></span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block">Carnegie Mellon University</span>,
            <span class="author-block">Florida Institute for Human and Machine Cognition</span>
            <br>
            <span class="author-block">Humanoids 2025</span>
          </div>
          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="https://linearwalking.github.io/" target="_blank" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="fas fa-file-pdf"></i></span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://linearwalking.github.io/" target="_blank" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="fab fa-github"></i></span>
                  <span>Code</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://linearwalking.github.io/" target="_blank" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="ai ai-arxiv"></i></span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section" style="background-color: #f9f9f9;">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Coming Soon!</h2>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser" style="background-color: #f0f8ff;">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <source src="static/videos/linearwalking3.mov"
        type="video/mp4">
      </video>
    </div>
  </div>
</section>

<section class="section" style="background-color: #f0f8ff;">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">TL;DR</h2>
        <div class="content has-text-justified">
          <p>
            When do locomotion controllers require reasoning about nonlinearities? In this work, we show that a whole-body model-predictive controller using a simple linear time-invariant approximation of the whole-body dynamics is able to execute basic locomotion tasks on complex legged robots. The formulation requires no online nonlinear dynamics evaluations or matrix inversions. We demonstrate walking, disturbance rejection, and even navigation to a goal position without a separate footstep planner on a quadrupedal robot. In addition, we demonstrate dynamic walking on a hydraulic humanoid, a robot with significant limb inertia, complex actuator dynamics, and large sim-to-real gap.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered" style="margin-bottom: 0.5rem;">Hardware Experiments</h2>
    
    <div class="columns is-multiline">
      
      <!-- Video 1 -->
      <div class="column is-half">
        <video autoplay controls muted loop width="100%">
          <source src="static/videos/forward_single.mp4" type="video/mp4">
        </video>
        <h2 class="subtitle has-text-centered">
          Humanoid walking forward with a 0.6 second swing phase and a 0.3 second flight phase (not quasi-static)
        </h2>
      </div>

      <!-- Video 2 -->
      <div class="column is-half">
        <video autoplay controls muted loop width="100%">
          <source src="static/videos/inplace_nadia.mp4" type="video/mp4">
        </video>
        <h2 class="subtitle has-text-centered">
          Humanoid walking in place for over a minute
        </h2>
      </div>

      <!-- Video 3 -->
      <div class="column is-half">
        <video autoplay controls muted loop width="100%">
          <source src="static/videos/ToHomeExperimentAllFast.mp4" type="video/mp4">
        </video>
        <h2 class="subtitle has-text-centered">
          Quadruped returning to the initial position without assistance from a footstep planner
        </h2>
      </div>

      <!-- Video 4 -->
      <div class="column is-half">
        <video autoplay controls muted loop width="100%">
          <source src="static/videos/perturbance.MOV" type="video/mp4">
        </video>
        <h2 class="subtitle has-text-centered">
          Quadruped perturbance recovery while stepping in place
        </h2>
      </div>

      <!-- Video 5 -->
      <div class="column is-half">
        <video autoplay controls muted loop width="100%">
          <source src="static/videos/jump.MOV" type="video/mp4">
        </video>
        <h2 class="subtitle has-text-centered">
          Quadruped jumping 
        </h2>
      </div>

      <!-- Video 6 -->
      <div class="column is-half">
        <video autoplay controls muted loop width="100%">
          <source src="static/videos/step.MOV" type="video/mp4">
        </video>
        <h2 class="subtitle has-text-centered">
          Quadruped stepping over a 24 cm box
        </h2>
      </div>

    </div>
  </div>
</section>





<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item has-text-centered">
        <!-- Your image here -->
        <img src="static/images/nadia_walk.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          The hydraulic humanoid Nadia walking forward over multiple steps using our convex MPC formulation with linear
          time-invariant dynamics constraints. The gait has a stride length of 30 cm, a swing phase of 0.6 s and a double support
          phase of 0.3 s.
        </h2>
      </div>
      <div class="item has-text-centered">
      <!-- Your image here -->
      <img src="static/images/inplace_figure.png" alt="MY ALT TEXT"/>
      <h2 class="subtitle has-text-centered">
        Top-down view of two perturbations applied to the
Unitree Go2 while stepping in place. The robot maintains
contact with the ground without slipping and return to its
original location.
      </h2>
    </div>
      <div class="item has-text-centered">
        <img src="static/images/home_figure_5.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          A Unitree Go2 robot starts from 10 initial conditions
with yaw from 5 to 90° and displacements from 0.1 to 1.7 m.
Transparent overlays show keyframes starting with 90° yaw
and 1.3 m displacement. Our controller is able to return to
the initial position without assistance from a footstep planner.
        </h2>
      </div>
      <div class="item has-text-centered">
        <img src="static/images/box_figure_3.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
         Keyframes of a Unitree Go2 robot stepping onto
a 24 cm box. The robot tracks a trajectory with up to
60 degrees joint deviation and 10 degrees pitch deviation
from the linearization pose, with the green dashed skeleton
showing the linearization pose.
     </div>
     <div class="item has-text-centered">
        <img src="static/images/nadia_tracking.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
        Foot and center-of-mass trajectories across six humanoid walking trials (black) over the desired foot placement
positions and center of mass trajectory (blue, dashed). Our controller is able to track the trajectory with minor deviations
despite large modeling errors.
     </div>
  </div>
</div>
</div>
</section>

<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3 has-text-centered">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">
            Youtube embed code here
            <iframe src="https://www.youtube.com/embed/QFMgxN6PRhM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- 
<section class="hero teaser" style="background-color: #f0f8ff;">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <source src="static/videos/push_simple.mp4"
        type="video/mp4">
      </video>
    </div>
  </div>
</section> 

<section class="section" style="background-color: #f9f9f9;">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">What is MPPI?</h2>
        <div class="content has-text-justified">
          <p>
            Model-Predictive Path Integral (MPPI) control is a gradient-free, sampling-based algorithm widely used in real-time control of complex systems. MPPI samples \( N \) control trajectories from a multivariate Gaussian distribution \( u_t \sim \mathcal{N}(\mu_t, \Sigma_t) \), where \( \mu_t \) is the mean control input at time \( t \), and \( \Sigma_t \) is the covariance matrix.
          </p>
          <p>
            For each sampled trajectory, the system is simulated forward to compute a corresponding state sequence, and a cumulative cost \( \mathcal{L}_n \) is computed for each trajectory. The weights of each trajectory are computed based on their min-max normalized cost:
          </p>
          <p style="text-align: center;">
            \[ \omega_n = \frac{\exp\!\left(-\frac{\mathcal{L}_n - \mathcal{L}_{\min}}{\lambda\,(\mathcal{L}_{\max} - \mathcal{L}_{\min})}\right)}{\sum_{n=1}^{N} \exp\!\left(-\frac{\mathcal{L}_n - \mathcal{L}_{\min}}{\lambda\,(\mathcal{L}_{\max} - \mathcal{L}_{\min})}\right)} \]
          </p>
          <p>
            The updated control input is then computed as the weighted average of the samples:
          </p>
          <p style="text-align: center;">
            \[ \mu_t = \sum_{n=1}^{N} \omega_n u_{n,t} \]
          </p>
          <p>
            where \( \mathcal{L}_n \) is the cost of the \( n \)-th trajectory, \( \omega_n \) is the corresponding weight, and \( \lambda \) is a temperature parameter that controls the sensitivity of the weighting to cost differences. Smaller \( \lambda \) makes the controller more selective to low-cost trajectories, while larger \( \lambda \) smooths the contribution of all samples.
          </p>
          <p>
            This process is applied in a receding horizon fashion, making MPPI suitable for real-time applications in systems with contact dynamics or high-dimensional state spaces.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser" style="background-color: #f9f9f9;">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <source src="static/videos/mppi_animation.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        MPPI explained
      </h2>
    </div>
  </div>
</section>

<section class="section" style="background-color: #f0f8ff;">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Overview</h2>
        <div class="content has-text-justified">
          <p>
            This paper presents a system for enabling real-time synthesis of whole-body locomotion and manipulation policies for real-world legged robots. Motivated by recent advancements in robot simulation, we leverage the efficient parallelization capabilities of the MuJoCo simulator to achieve fast sampling over the robot state and action trajectories. Our results show surprisingly effective real-world locomotion and manipulation capabilities with a very simple control strategy. We demonstrate our approach on several hardware and simulation experiments: robust locomotion over flat and uneven terrains, climbing over a box whose height is comparable to the robot, and pushing a box to a goal position. To our knowledge, this is the first successful deployment of whole-body sampling-based MPC on real-world legged robot hardware.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser" style="background-color: #4a4a4a; color: white; padding: 1rem 0;">
  <div class="container is-max-desktop" style="margin-top: 1rem">
    <div class="hero-body">
      <h2 class="title is-3 has-text-centered" style="color: white; margin-bottom: 1.5rem;">
        Key Design Choices
      </h2>
      <figure class="image" style="margin: 0 auto; max-width: 100%;">
        <img src="static/images/key_design.png" alt="Teaser Image" id="teaser-image" height="100%">
      </figure>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered" style="margin-bottom: 0.5rem;">Hardware Experiments</h2>
  </div>
</section>


<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <source src="static/videos/push.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Quadruped pushing a box to a desired location
      </h2>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <source src="static/videos/climb.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Quadruped climbing up and down a box of its own height
      </h2>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <source src="static/videos/walking.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Quadruped walking in a clockwise hexagon trajectory under small to moderate model mismatch and external disturbance
      </h2>
    </div>
  </div>
</section>

<section class="hero is-small is-light" style="background-color: #f0f8ff;">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3 has-text-centered">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <div class="publication-video">
            <video controls autoplay muted loop>
              <source src="static/videos/ICRA25_2966_VI_i.mp4" type="video/mp4">
              Your browser does not support the video tag.
            </video>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
-->

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{bishop2025linearwalking,
      title={The Surprising Effectiveness of Linear Models for Whole-Body Model-Predictive Control},
      author={Bishop, Arun and Alvarez-Padilla, Juan and Schoedel, Sam and Sow, Ibrahima S. and Chandrachud, Juee and Sharma, Sheitej and Kraus, Will and Park, Beomyeong and Griffin, Robert J.},
      url = {TBD},
      booktitle = {IEEE International Conference on Humanoid Robots},
      year={2025},
    }</code></pre>
  </div>
</section> 


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>


  </body>
  </html>
